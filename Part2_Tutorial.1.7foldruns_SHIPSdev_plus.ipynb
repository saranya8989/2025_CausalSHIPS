{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2903f5d7",
   "metadata": {},
   "source": [
    "# Tutorial 2.1\n",
    "This notebook goes through the critical steps of the causal feature selection workflow on the SHIPS developmental data, similar to the first notebook of Part 1. Please run this notebook before you do anything else as the results produced in this notebook are reused in the subsequent Part 2 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1323ec-5c0d-408b-bfd3-c85fa57e060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fredericktam/anaconda3/envs/AMSsat/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nf\n",
    "from netCDF4 import Dataset\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast,gc,pickle\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Custom packages\n",
    "import read_config\n",
    "from util.data_process import read_vars, proc_dataset, miss\n",
    "from util.models import performance_scores,train_baseline,causal_settings,train_PC1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480d0a5",
   "metadata": {},
   "source": [
    "## Useful functions and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc3951-d6e2-4294-9191-4f5d044a7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to save models with pickle\n",
    "def save_models(models, filename):\n",
    "    with open(filename,'wb') as f:\n",
    "        pickle.dump(models, f)\n",
    "\n",
    "\n",
    "def read_pickle(filepath=None):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "    return x\n",
    "\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01913bbd-3794-4dbe-9aac-19564ad3162a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read configuration file\n",
    "config_set = read_config.read_config()\n",
    "#config_set = read_config.read_config('./config.ini')\n",
    "# Define Target\n",
    "if int(config_set['target_lag'])==20:\n",
    "    target='delv120'\n",
    "if int(config_set['target_lag'])==16:\n",
    "    target='delv96'\n",
    "if int(config_set['target_lag'])==12:\n",
    "    target='delv72'\n",
    "if int(config_set['target_lag'])==8:\n",
    "    target='delv48'\n",
    "if int(config_set['target_lag'])==4:\n",
    "    target='delv24'\n",
    "#seeds = np.arange(100,131,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebad58-a15d-4857-84f4-c5873fda3a3f",
   "metadata": {},
   "source": [
    "## Loops through the 7 splits of SHIPSPLUS data (with causal predictors) and runs PC_stable in Tigramite for given pc_alpha values, creates results pkl inside results/4/shipsnew/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadb236-a8b9-42e5-8cf7-8771cd992a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:00<00:00,  2.50s/it]\n",
      "100%|██████████| 24/24 [01:03<00:00,  2.65s/it]\n",
      "100%|██████████| 24/24 [01:05<00:00,  2.73s/it]\n",
      "100%|██████████| 24/24 [00:57<00:00,  2.40s/it]\n",
      "100%|██████████| 24/24 [01:06<00:00,  2.78s/it]\n",
      "100%|██████████| 24/24 [00:59<00:00,  2.47s/it]\n",
      "100%|██████████| 24/24 [00:51<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in range(7):  # Assuming 0 through 6\n",
    "    # Load the processed time series data for the current split\n",
    "    split_path = f'./proc/pickle/delv24/dict_split{split}.pkl'\n",
    "    with open(split_path, 'rb') as f:\n",
    "        TIDATA = pickle.load(f)\n",
    "    # Tigramite needs the column names (variable names) of our data\n",
    "    var_names = TIDATA['Xnorml']['train'][list(TIDATA['Xnorml']['train'].keys())[0]].columns\n",
    "    # Define the initial causal relationships for the experiment. Refer to the tigramite tutorial if you would like to learn how to create a \n",
    "    # causal relationship dictionary of your own.\n",
    "    onlyships_lag = causal_settings.link_onlyships(\n",
    "        numvar=TIDATA['aligned_train'][list(TIDATA['aligned_train'].keys())[0]].shape[1],\n",
    "        lag=4, #24 hours\n",
    "        target_ind=[0], #The convention of our processed time series = the target (delv24) is always placed in the first columh\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    # We loop through different pc_alpha settings to test the sensitivity of significance levels to our results\n",
    "    for pc_alpha in tqdm([0.0001, 0.00015 ,0.001,0.0015,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,\n",
    "                      0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6]):\n",
    "        # Tigramite does not recognize np.nan, so we change them to -999.0 (which tigramite recogizes as missing values)\n",
    "        Xnorml_c = {\n",
    "            'train': {ind: np.asarray(TIDATA['Xnorml']['train'][key].replace(np.nan, -999.0))\n",
    "                      for ind, key in enumerate(TIDATA['Xnorml']['train'].keys())},\n",
    "            'valid': {ind: np.asarray(TIDATA['Xnorml']['valid'][key].replace(np.nan, -999.0))\n",
    "                      for ind, key in enumerate(TIDATA['Xnorml']['valid'].keys())},\n",
    "            'test': {ind: np.asarray(TIDATA['Xnorml']['test'][key].replace(np.nan, -999.0))\n",
    "                     for ind, key in enumerate(TIDATA['Xnorml']['test'].keys())}\n",
    "        }\n",
    "        # Here we run tigramite with the all of our settings. Our prediction task only uses information gathered at a given time and not past information to make predictions,\n",
    "        # Thus, tau_min0 and tau_max0 are the same.\n",
    "        result = train_PC1.Pipeline(\n",
    "            Xnorml_c['train'],\n",
    "            pc_alpha,\n",
    "            pc_type='run_pcstable',\n",
    "            tau_min0=int(config_set['tau_min']), \n",
    "            tau_max0=int(config_set['tau_max']),\n",
    "            var_name=var_names,\n",
    "            link_assumptions=onlyships_lag\n",
    "        ).run_tigramite()\n",
    "\n",
    "        del Xnorml_c\n",
    "        gc.collect()\n",
    "        results.append(result)\n",
    "\n",
    "    savetos = {\n",
    "        'dataframes': TIDATA['Xnorml'],\n",
    "        'PC1_results': results,\n",
    "        'var_names': var_names\n",
    "    }\n",
    "\n",
    "    output_dir = f'results/{int(config_set[\"target_lag\"])}/shipsnew/'\n",
    "    output_path = f'{output_dir}results_fold_{split}.pkl'\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(output_path, 'wb') as handler:\n",
    "        pickle.dump(savetos, handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38201594-1584-43aa-bd66-e8f9ea4295cf",
   "metadata": {},
   "source": [
    "## Loops through the 7 splits of SHIPS developmental data and runs PC_stable in Tigramite for given pc_alpha values, creates results pkl inside results/4/shipsold/\n",
    "\n",
    "The loop below is exactly the same as the loop to create the SHIPS+ results. The only difference is that we read in the original SHIPS developmental data (olddict*) for Tigramite calculation and not the new SHIPS+ data (dict_*) with the additional predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efba79f4-3591-459b-91f2-319f9219e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:44<00:00,  1.85s/it]\n",
      "100%|██████████| 24/24 [00:42<00:00,  1.78s/it]\n",
      "100%|██████████| 24/24 [00:40<00:00,  1.68s/it]\n",
      "100%|██████████| 24/24 [00:33<00:00,  1.38s/it]\n",
      "100%|██████████| 24/24 [00:49<00:00,  2.08s/it]\n",
      "100%|██████████| 24/24 [00:41<00:00,  1.73s/it]\n",
      "100%|██████████| 24/24 [00:37<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in range(7):  # Assuming 0 through 6\n",
    "    # Load the current split\n",
    "    split_path = f'proc/pickle/delv24/olddict_split{split}.pkl'\n",
    "    with open(split_path, 'rb') as f:\n",
    "        TIDATA = pickle.load(f)\n",
    "\n",
    "    var_names = TIDATA['Xnorml']['train'][list(TIDATA['Xnorml']['train'].keys())[0]].columns\n",
    "\n",
    "    onlyships_lag = causal_settings.link_onlyships(\n",
    "        numvar=TIDATA['aligned_train'][list(TIDATA['aligned_train'].keys())[0]].shape[1],\n",
    "        lag=4,\n",
    "        target_ind=[0],\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for pc_alpha in tqdm([0.0001, 0.00015, 0.001, 0.0015, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08,\n",
    "                         0.09, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]):\n",
    "        Xnorml_c = {\n",
    "            'train': {ind: np.asarray(TIDATA['Xnorml']['train'][key].replace(np.nan, -999.0))\n",
    "                      for ind, key in enumerate(TIDATA['Xnorml']['train'].keys())},\n",
    "            'valid': {ind: np.asarray(TIDATA['Xnorml']['valid'][key].replace(np.nan, -999.0))\n",
    "                      for ind, key in enumerate(TIDATA['Xnorml']['valid'].keys())},\n",
    "            'test': {ind: np.asarray(TIDATA['Xnorml']['test'][key].replace(np.nan, -999.0))\n",
    "                     for ind, key in enumerate(TIDATA['Xnorml']['test'].keys())}\n",
    "        }\n",
    "\n",
    "        result = train_PC1.Pipeline(\n",
    "            Xnorml_c['train'],\n",
    "            pc_alpha,\n",
    "            pc_type='run_pcstable',\n",
    "            tau_min0=int(config_set['tau_min']),\n",
    "            tau_max0=int(config_set['tau_max']),\n",
    "            var_name=var_names,\n",
    "            link_assumptions=onlyships_lag\n",
    "        ).run_tigramite()\n",
    "\n",
    "        del Xnorml_c\n",
    "        gc.collect()\n",
    "        results.append(result)\n",
    "\n",
    "    savetos = {\n",
    "        'dataframes': TIDATA['Xnorml'],\n",
    "        'PC1_results': results,\n",
    "        'var_names': var_names\n",
    "    }\n",
    "\n",
    "    output_dir = f'results/{int(config_set[\"target_lag\"])}/shipsold/'\n",
    "    output_path = f'{output_dir}results_fold_{split}.pkl'\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(output_path, 'wb') as handler:\n",
    "        pickle.dump(savetos, handler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMSsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
